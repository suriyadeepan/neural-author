{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "import hickle as hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 329\n",
      "[' CHAPTER I. PREJUDICES OF PHILOSOPHERS'] ['135. Pharisaism is not a deterioration of the good man; a considerable part of it is rather an essential condition of being good.'] ['296. Alas! what are you, after all, my written and painted thoughts! Not long ago you were so variegated, young and malicious, so full of thorns and secret spices, that you made me sneeze and laugh\\xe2\\x80\\x94and now? You have already doffed your novelty, and some of you, I fear, are ready to become truths, so immortal do they look, so pathetically honest, so tedious! And was it ever otherwise? What then do we write and paint, we mandarins with Chinese brush, we immortalisers of things which LEND themselves to writing, what are we alone capable of painting? Alas, only that which is just about to fade and begins to lose its odour! Alas, only exhausted and departing storms and belated yellow sentiments! Alas, only birds strayed and fatigued by flight, which now let themselves be captured with the hand\\xe2\\x80\\x94with OUR hand! We immortalize what cannot live and fly much longer, things only which are exhausted and mellow! And it is only for your AFTERNOON, you, my written and painted thoughts, for which alone I have colours, many colours, perhaps, many variegated softenings, and fifty yellows and browns and greens and reds;\\xe2\\x80\\x94but nobody will divine thereby how ye looked in your morning, you sudden sparks and marvels of my solitude, you, my old, beloved\\xe2\\x80\\x94EVIL thoughts!']\n"
     ]
    }
   ],
   "source": [
    "# prepare corpus\n",
    "src_corpus = hkl.load('../dataset/beyond.hkl')\n",
    "print len(src_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = ''\n",
    "for verse in src_corpus:\n",
    "    corpus = corpus + str(verse[0]) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected string, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d1030fafd572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected string, list found"
     ]
    }
   ],
   "source": [
    "corpus = '\\n'.join(src_corpus)\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isPureAscii(msg):\n",
    "    return all(ord(c) < 128 for c in msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "en_src_corpus = []\n",
    "for msg in src_corpus:\n",
    "    if isPureAscii(msg):\n",
    "        en_src_corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = '\\n'.join(en_src_corpus)\n",
    "#print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "VOCABULARY = set(corpus)\n",
    "VOCAB_SIZE = len(VOCABULARY)\n",
    "print VOCAB_SIZE\n",
    "\n",
    "CHAR2IX = {c: i for i,c in enumerate(VOCABULARY)}\n",
    "IX2CHAR = {i: c for i,c in enumerate(VOCABULARY)}\n",
    "CHAR_TO_ONEHOT = {c: np.eye(VOCAB_SIZE)[i] for i,c in enumerate(VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 50\n",
    "BATCH_SIZE = 50\n",
    "RNN_HIDDEN_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_train = corpus[:(len(corpus)*9 // 10)]\n",
    "corpus_valid = corpus[(len(corpus)*9//10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly pick sentences \n",
    "def data_batch_generator(corpus, size=BATCH_SIZE):\n",
    "    idx0 = np.random.randint(0,len(corpus) - SEQ_LENGTH -1,size=size)\n",
    "    \n",
    "    while True:\n",
    "        items = np.array([corpus[start:start + SEQ_LENGTH + 1] for start in idx0])\n",
    "        idx0 = (idx0 + SEQ_LENGTH) % (len(corpus) - SEQ_LENGTH - 1)\n",
    "        yield items    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' and has a lynx-eye for the weak points in those na']\n",
      "['atures to whose elevations he cannot attain. He is ']\n",
      "[' confiding, yet only as one who lets himself go, bu']\n"
     ]
    }
   ],
   "source": [
    "# testing batch generator\n",
    "gen = data_batch_generator(corpus,size=1)\n",
    "print(next(gen))\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After sampling a data batch, we transform it into a one hot feature representation\n",
    "# and create a target sequence by shifting by one character\n",
    "def prep_batch_for_network(batch):\n",
    "    x_seq = np.zeros((len(batch), SEQ_LENGTH, VOCAB_SIZE), dtype='float32')\n",
    "    y_seq = np.zeros((len(batch), SEQ_LENGTH), dtype='int32')\n",
    "\n",
    "    for i, item in enumerate(batch):\n",
    "        for j in range(SEQ_LENGTH):\n",
    "            x_seq[i, j] = CHAR_TO_ONEHOT[item[j]]\n",
    "            y_seq[i, j] = CHAR2IX[item[j + 1]]\n",
    "\n",
    "    return x_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Symbolic variables for input. In addition to the usual features and target,\n",
    "# we need initial values for the RNN layer's hidden states\n",
    "x_sym = T.tensor3()\n",
    "y_sym = T.imatrix()\n",
    "hid_init_sym = T.matrix()\n",
    "hid2_init_sym = T.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our network has two stacked GRU layers processing the input sequence.\n",
    "# Before the decoder layer, we need to reshape the sequence into the batch dimension,\n",
    "# so that timesteps are decoded independently.\n",
    "l_input = lasagne.layers.InputLayer((None, SEQ_LENGTH, VOCAB_SIZE))\n",
    "\n",
    "l_rnn = lasagne.layers.GRULayer(l_input,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid_init_sym,\n",
    "                                  )\n",
    "\n",
    "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid2_init_sym,\n",
    "                                  )\n",
    "\n",
    "\n",
    "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
    "\n",
    "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
    "                                      num_units=VOCAB_SIZE,\n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, SEQ_LENGTH, VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n"
     ]
    }
   ],
   "source": [
    "# We extract the hidden state of each GRU layer as well as the output of the decoder.\n",
    "# Only the hidden state at the last timestep is needed\n",
    "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out],\n",
    "                                                        {l_input: x_sym})\n",
    "\n",
    "hid_out = hid_out[:, -1]\n",
    "hid2_out = hid2_out[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We flatten the sequence into the batch dimension before calculating the loss\n",
    "def calc_cross_ent(net_output, targets):\n",
    "    preds = T.reshape(net_output, (-1, VOCAB_SIZE))\n",
    "    targets = T.flatten(targets)\n",
    "    cost = T.nnet.categorical_crossentropy(preds, targets)\n",
    "    return cost\n",
    "\n",
    "loss = T.mean(calc_cross_ent(prob_out, y_sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For stability during training, gradients are clipped and a total gradient norm constraint is also used\n",
    "MAX_GRAD_NORM = 15\n",
    "\n",
    "all_params = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "all_grads = T.grad(loss, all_params)\n",
    "all_grads = [T.clip(g, -5, 5) for g in all_grads]\n",
    "all_grads, norm = lasagne.updates.total_norm_constraint(\n",
    "    all_grads, MAX_GRAD_NORM, return_norm=True)\n",
    "\n",
    "updates = lasagne.updates.adam(all_grads, all_params, learning_rate=0.002)\n",
    "\n",
    "f_train = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym],\n",
    "                          [loss, norm, hid_out, hid2_out],\n",
    "                          updates=updates\n",
    "                         )\n",
    "\n",
    "f_val = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym], [loss, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 50.\nApply node that caused the error: GpuElemwise{Composite{(((i0 - Composite{scalar_sigmoid((i0 + i1))}(i1, i2)) * i3) + (Composite{scalar_sigmoid((i0 + i1))}(i1, i2) * tanh((i4 + (scalar_sigmoid((i5 + i6)) * i7)))))},no_inplace}(CudaNdarrayConstant{[[ 1.]]}, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, <CudaNdarrayType(float32, matrix)>, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0)\nToposort index: 7\nInputs types: [CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\n\nHINT: Use another linker then the c linker to have the inputs shapes and strides printed.\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuJoin.0)\nToposort index: 145\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (50, 50, 600), (51, 1, 200), (200, 600)]\nInputs strides: [(), (30000, 600, 1), (200, 0, 1), (600, 1)]\nInputs values: [array(50), 'not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1}), GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-9fc8051e4ffb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_batch_for_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m250\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    619\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    295\u001b[0m     exc_value = exc_type(str(exc_value) + detailed_err_msg +\n\u001b[0;32m    296\u001b[0m                          '\\n' + '\\n'.join(hints))\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    833\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    834\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 835\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    822\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    825\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/jabroni/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/scan_perform/mod.cpp:3681)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    295\u001b[0m     exc_value = exc_type(str(exc_value) + detailed_err_msg +\n\u001b[0;32m    296\u001b[0m                          '\\n' + '\\n'.join(hints))\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/jabroni/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/scan_perform/mod.cpp:3613)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 50.\nApply node that caused the error: GpuElemwise{Composite{(((i0 - Composite{scalar_sigmoid((i0 + i1))}(i1, i2)) * i3) + (Composite{scalar_sigmoid((i0 + i1))}(i1, i2) * tanh((i4 + (scalar_sigmoid((i5 + i6)) * i7)))))},no_inplace}(CudaNdarrayConstant{[[ 1.]]}, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, <CudaNdarrayType(float32, matrix)>, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0)\nToposort index: 7\nInputs types: [CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\n\nHINT: Use another linker then the c linker to have the inputs shapes and strides printed.\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuJoin.0)\nToposort index: 145\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (50, 50, 600), (51, 1, 200), (200, 600)]\nInputs strides: [(), (30000, 600, 1), (200, 0, 1), (600, 1)]\nInputs values: [array(50), 'not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1}), GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# Training takes a while - you may want to skip this and the next cell, and load the pretrained weights instead\n",
    "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "\n",
    "train_batch_gen = data_batch_generator(corpus_train)\n",
    "\n",
    "for iteration in range(20000):\n",
    "    x, y = prep_batch_for_network(next(train_batch_gen))\n",
    "    loss_train, norm, hid, hid2 = f_train(x, y, hid, hid2)\n",
    "    \n",
    "    if iteration % 250 == 0:\n",
    "        print('Iteration {}, loss_train: {}, norm: {}'.format(iteration, loss_train, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_values = lasagne.layers.get_all_param_values(l_out)\n",
    "d = {'param values': param_values,\n",
    "     'VOCABULARY': VOCABULARY, \n",
    "     'CHAR2IX': CHAR2IX,\n",
    "     'IX2CHAR': IX2CHAR,\n",
    "    }\n",
    "import hickle \n",
    "hickle.dump(param_values,'nietzsche_gru_2layer_trained_param_values.pkl')\n",
    "#pickle.dump(d, open('gru_2layer_trained.pkl','w'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.84334\n"
     ]
    }
   ],
   "source": [
    "# Calculate validation loss\n",
    "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "\n",
    "val_batch_gen = data_batch_generator(corpus_valid)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for iteration in range(50):\n",
    "    x, y = prep_batch_for_network(next(val_batch_gen))\n",
    "    loss_val, hid, hid2 = f_val(x, y, hid, hid2)\n",
    "    losses.append(loss_val)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For faster sampling, we rebuild the network with a sequence length of 1\n",
    "l_input = lasagne.layers.InputLayer((None, 1, VOCAB_SIZE))\n",
    "\n",
    "l_rnn = lasagne.layers.GRULayer(l_input,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid_init_sym,\n",
    "                                  )\n",
    "\n",
    "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
    "                                  num_units=RNN_HIDDEN_SIZE,\n",
    "                                  grad_clipping=5.,\n",
    "                                  hid_init=hid2_init_sym,\n",
    "                                  )\n",
    "\n",
    "\n",
    "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
    "\n",
    "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
    "                                      num_units=VOCAB_SIZE,\n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, 1, VOCAB_SIZE))\n",
    "\n",
    "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out], {\n",
    "                        l_input: x_sym,\n",
    "                    })\n",
    "hid_out = hid_out[:, -1]\n",
    "hid2_out = hid2_out[:, -1]\n",
    "prob_out = prob_out[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(l_out, d['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out, hid_out, hid2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will use random sentences from the validation corpus to 'prime' the network\n",
    "primers = corpus_valid.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMER: 293. A man who says: \"I like that, I take it for my own, and mean to guard and protect it from every one\"; a man who can conduct a case, carry out a resolution, remain true to an opinion, keep hold of a woman, punish and overthrow insolence; a man who has his indignation and his sword, and to whom the weak, the suffering, the oppressed, and even the animals willingly submit and naturally belong; in short, a man who is a MASTER by nature—when such a man has sympathy, well! THAT sympathy has value! But of what account is the sympathy of those who suffer! Or of those even who preach sympathy! There is nowadays, throughout almost the whole of Europe, a sickly irritability and sensitiveness towards pain, and also a repulsive irrestrainableness in complaining, an effeminizing, which, with the aid of religion and philosophical nonsense, seeks to deck itself out as something superior—there is a regular cult of suffering. The UNMANLINESS of that which is called \"sympathy\" by such groups of visionaries, is always, I believe, the first thing that strikes the eye.—One must resolutely and radically taboo this latest form of bad taste; and finally I wish people to put the good amulet, \"GAI SABER\" (\"gay science,\" in ordinary language), on heart and neck, as a protection against it.\n",
      "\n",
      "GENERATED: 1107. The commanding and obeying over-aguiated, and in generally be means of a defection an insugnitive, believing left which is thus life-artiste, and Christian possession, so much our Vedtified From plaifising of all the real potes in which disguised epochs and obligation, and \"I am morality in it), but like a fiction belongs to the were ourselves, that thinks with giviz. Thas the increasing physiologicing and liberties: \"What morality do by this bell-critical or a corps in cases or else thene\n"
     ]
    }
   ],
   "source": [
    "# We feed character one at a time from the priming sequence into the network.\n",
    "# To obtain a sample string, at each timestep we sample from the output probability distribution,\n",
    "# and feed the chosen character back into the network. We terminate after the first linebreak.\n",
    "sentence = ''\n",
    "hid = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "hid2 = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
    "x = np.zeros((1, 1, VOCAB_SIZE), dtype='float32')\n",
    "\n",
    "primer = np.random.choice(primers) + '\\n'\n",
    "\n",
    "for c in primer:\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    x[0, 0, :] = CHAR_TO_ONEHOT[c]\n",
    "    \n",
    "for _ in range(500):\n",
    "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
    "    p = p/(1 + 1e-6)\n",
    "    s = np.random.multinomial(1, p)\n",
    "    sentence += IX2CHAR[s.argmax(-1)]\n",
    "    x[0, 0, :] = s\n",
    "    if sentence[-1] == '\\n':\n",
    "        break\n",
    "        \n",
    "print('PRIMER: ' + primer)\n",
    "print('GENERATED: ' + sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
